import asyncio
import logging
import redis
import json
import datetime
import pytz
from app.config import settings
from utils.postgres_service import insert_messages

logging.basicConfig(level=logging.INFO)


class RedisCleanupService:
    """Redisç¼“å­˜æ¸…ç†æœåŠ¡ï¼Œè´Ÿè´£å®šæœŸæ¸…ç†è¿‡æœŸçš„èŠå¤©è®°å½•å¹¶å½’æ¡£åˆ°PostgreSQL"""

    def __init__(self):
        self.redis_client = redis.StrictRedis.from_url(
            settings.REDIS_URL, decode_responses=True
        )
        self.cleanup_interval = 2 * 60 * 60  # 2å°æ—¶è¿è¡Œä¸€æ¬¡æ¸…ç†
        self.retention_seconds = 48 * 60 * 60  # 48å°æ—¶ä¿ç•™æ—¶é—´
        self.min_keep_count = 1000  # æ— è®ºè¿‡æœŸå¤šä¹…éƒ½ä¿ç•™çš„æœ€è¿‘è®°å½•æ•°é‡

    async def start_cleanup_scheduler(self):
        """å¯åŠ¨å®šæœŸæ¸…ç†ä»»åŠ¡"""
        logging.info("ğŸ”„ å¯åŠ¨Redisç¼“å­˜æ¸…ç†æœåŠ¡...")
        while True:
            try:
                await self.cleanup_expired_messages()
                await asyncio.sleep(self.cleanup_interval)
            except Exception as e:
                logging.error(f"âŒ Redisæ¸…ç†æœåŠ¡å‡ºé”™: {e}")
                await asyncio.sleep(60)  # å‡ºé”™æ—¶ç­‰å¾…1åˆ†é’Ÿåé‡è¯•

    async def cleanup_expired_messages(self):
        """æ¸…ç†æ‰€æœ‰é¢‘é“çš„è¿‡æœŸæ¶ˆæ¯"""
        try:
            # è·å–æ‰€æœ‰èŠå¤©è®°å½•çš„Redisé”®
            channel_keys = self.redis_client.keys("channel_memory:*")

            if not channel_keys:
                logging.info("ğŸ” æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ¸…ç†çš„èŠå¤©è®°å½•")
                return

            logging.info(f"ğŸ” å¼€å§‹æ¸…ç† {len(channel_keys)} ä¸ªé¢‘é“çš„è¿‡æœŸæ¶ˆæ¯...")

            total_archived = 0
            total_deleted = 0

            for channel_key in channel_keys:
                channel_id = channel_key.split(":")[1]
                archived, deleted = await self.cleanup_channel_messages(channel_id)
                total_archived += archived
                total_deleted += deleted

            if total_archived > 0 or total_deleted > 0:
                logging.info(
                    f"âœ… æ¸…ç†å®Œæˆ: å½’æ¡£ {total_archived} æ¡æ¶ˆæ¯, åˆ é™¤ {total_deleted} æ¡è¿‡æœŸæ¶ˆæ¯"
                )
            else:
                logging.info("âœ… æ¸…ç†å®Œæˆ: æ²¡æœ‰è¿‡æœŸæ¶ˆæ¯éœ€è¦å¤„ç†")

        except Exception as e:
            logging.error(f"âŒ æ¸…ç†è¿‡æœŸæ¶ˆæ¯æ—¶å‡ºé”™: {e}")

    async def cleanup_channel_messages(self, channel_id: str):
        """æ¸…ç†æŒ‡å®šé¢‘é“çš„è¿‡æœŸæ¶ˆæ¯ï¼Œä½†å§‹ç»ˆä¿ç•™æœ€è¿‘çš„25æ¡è®°å½•"""
        try:
            # ä½¿ç”¨ä¸œå…«åŒºæ—¶é—´
            tz = pytz.timezone("Asia/Shanghai")
            now_timestamp = datetime.datetime.now(tz).timestamp()
            retention_cutoff_timestamp = now_timestamp - self.retention_seconds

            channel_key = f"channel_memory:{channel_id}"
            
            # è·å–å½“å‰é¢‘é“çš„æ€»æ¶ˆæ¯æ•°é‡
            total_count = self.redis_client.zcard(channel_key)
            
            if total_count <= self.min_keep_count:
                # å¦‚æœæ€»æ•°ä¸è¶…è¿‡æœ€å°ä¿ç•™æ•°é‡ï¼Œä¸è¿›è¡Œä»»ä½•æ¸…ç†
                logging.info(f"ğŸ“‹ é¢‘é“ {channel_id}: æ€»æ¶ˆæ¯æ•° {total_count} <= {self.min_keep_count}ï¼Œè·³è¿‡æ¸…ç†")
                return 0, 0

            # è·å–æ‰€æœ‰æ¶ˆæ¯ï¼ŒæŒ‰æ—¶é—´æˆ³å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            # æ³¨æ„ï¼šä½ çš„æ•°æ®ä¸­ï¼Œmemberæ˜¯JSONå­—ç¬¦ä¸²ï¼Œscoreæ˜¯æ—¶é—´æˆ³
            all_messages = self.redis_client.zrevrange(
                channel_key, 0, -1, withscores=True
            )
            
            if len(all_messages) <= self.min_keep_count:
                logging.info(f"ğŸ“‹ é¢‘é“ {channel_id}: å®é™…æ¶ˆæ¯æ•° {len(all_messages)} <= {self.min_keep_count}ï¼Œè·³è¿‡æ¸…ç†")
                return 0, 0

            # ç¡®å®šè¦ä¿ç•™çš„æ¶ˆæ¯ï¼ˆæœ€æ–°çš„25æ¡ï¼‰
            messages_to_keep = all_messages[:self.min_keep_count]
            
            # æ‰¾å‡ºéœ€è¦åˆ é™¤çš„è¿‡æœŸæ¶ˆæ¯ï¼ˆè¶…è¿‡8å°æ—¶ä¸”ä¸åœ¨æœ€æ–°25æ¡ä¸­ï¼‰
            messages_to_delete = []
            for message_json, timestamp in all_messages[self.min_keep_count:]:  # ä»ç¬¬26æ¡å¼€å§‹æ£€æŸ¥
                if timestamp < retention_cutoff_timestamp:
                    messages_to_delete.append((message_json, timestamp))

            if not messages_to_delete:
                logging.info(f"ğŸ“‹ é¢‘é“ {channel_id}: æ²¡æœ‰éœ€è¦æ¸…ç†çš„è¿‡æœŸæ¶ˆæ¯")
                return 0, 0

            # æ‰¹é‡åˆ é™¤è¿‡æœŸæ¶ˆæ¯
            deleted_count = 0
            for message_json, timestamp in messages_to_delete:
                # åˆ é™¤ç‰¹å®šçš„æ¶ˆæ¯ï¼ˆä½¿ç”¨JSONå­—ç¬¦ä¸²ä½œä¸ºmemberï¼‰
                removed = self.redis_client.zrem(channel_key, message_json)
                if removed:
                    deleted_count += 1
                    # å¯é€‰ï¼šè§£ææ¶ˆæ¯å†…å®¹ç”¨äºæ—¥å¿—è®°å½•
                    try:
                        msg_data = json.loads(message_json)
                        msg_time = datetime.datetime.fromtimestamp(timestamp, tz).strftime("%Y-%m-%d %H:%M:%S")
                        logging.debug(f"åˆ é™¤æ¶ˆæ¯: {msg_time} - {msg_data.get('role', 'unknown')}")
                    except:
                        pass  # å¿½ç•¥JSONè§£æé”™è¯¯

            if deleted_count > 0:
                remaining_count = self.redis_client.zcard(channel_key)
                logging.info(
                    f"ğŸ§¹ é¢‘é“ {channel_id}: åˆ é™¤ {deleted_count} æ¡è¿‡æœŸæ¶ˆæ¯ï¼Œ"
                    f"ä¿ç•™ {remaining_count} æ¡æ¶ˆæ¯ï¼ˆåŒ…å«æœ€è¿‘ {self.min_keep_count} æ¡ï¼‰"
                )

            return 0, deleted_count

        except Exception as e:
            logging.error(f"âŒ æ¸…ç†é¢‘é“ {channel_id} æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            return 0, 0

    async def cleanup_abandoned_buffers(self):
        """æ¸…ç†è¢«é—å¼ƒçš„æ¶ˆæ¯ç¼“å†²åŒºï¼ˆå¯é€‰åŠŸèƒ½ï¼‰"""
        try:
            # è·å–æ‰€æœ‰æ¶ˆæ¯ç¼“å†²åŒºçš„é”®
            buffer_keys = self.redis_client.keys("channel_buffer:*")

            if not buffer_keys:
                return

            logging.info(f"ğŸ§¹ æ£€æŸ¥ {len(buffer_keys)} ä¸ªæ¶ˆæ¯ç¼“å†²åŒº...")

            cleaned_count = 0
            for buffer_key in buffer_keys:
                # æ£€æŸ¥ç¼“å†²åŒºæ˜¯å¦è¶…è¿‡10åˆ†é’Ÿæ²¡æœ‰æ´»åŠ¨
                # è¿™é‡Œå¯ä»¥é€šè¿‡è®¾ç½®TTLæˆ–è€…å…¶ä»–æ–¹å¼æ¥åˆ¤æ–­
                buffer_length = self.redis_client.llen(buffer_key)
                if buffer_length > 0:
                    # å¯ä»¥è®¾ç½®ç¼“å†²åŒºçš„TTLï¼Œè¶…æ—¶è‡ªåŠ¨åˆ é™¤
                    # æˆ–è€…æ ¹æ®ä¸šåŠ¡é€»è¾‘åˆ¤æ–­æ˜¯å¦éœ€è¦æ¸…ç†
                    pass

            if cleaned_count > 0:
                logging.info(f"ğŸ§¹ æ¸…ç†äº† {cleaned_count} ä¸ªè¢«é—å¼ƒçš„æ¶ˆæ¯ç¼“å†²åŒº")

        except Exception as e:
            logging.error(f"âŒ æ¸…ç†è¢«é—å¼ƒç¼“å†²åŒºæ—¶å‡ºé”™: {e}")


# å•ä¾‹å®ä¾‹
cleanup_service = RedisCleanupService()


async def start_redis_cleanup():
    """å¯åŠ¨Redisæ¸…ç†æœåŠ¡çš„å…¥å£å‡½æ•°"""
    await cleanup_service.start_cleanup_scheduler()


if __name__ == "__main__":
    asyncio.run(start_redis_cleanup())