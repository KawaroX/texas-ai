# Texas AI é¡¹ç›®æ”¹è¿›å»ºè®®

ç”Ÿæˆæ—¥æœŸ: 2025-12-12

## ğŸ”´ é«˜ä¼˜å…ˆçº§ - ç«‹å³å¤„ç†

### 1. ä¿®å¤ç½‘ç»œè¯·æ±‚è¶…æ—¶é—®é¢˜ âœ… å·²ä¿®å¤
- **é—®é¢˜**: `generate_daily_life_task` ä½¿ç”¨é»˜è®¤çš„ 5 ç§’è¶…æ—¶ï¼Œå¯¼è‡´ç”Ÿæˆä»»åŠ¡æ€»æ˜¯å¤±è´¥
- **å½±å“**: æ¯æ—¥æ—¥ç¨‹æ— æ³•è‡ªåŠ¨ç”Ÿæˆ
- **è§£å†³æ–¹æ¡ˆ**: å·²å°†è¶…æ—¶æ—¶é—´è®¾ç½®ä¸º 300 ç§’
- **ä½ç½®**: `tasks/daily_tasks.py:225`

### 2. æ¸…ç†è°ƒè¯•ä»£ç 
**é—®é¢˜**: é¡¹ç›®ä¸­å­˜åœ¨å¤§é‡ `print()` è¯­å¥å’Œè°ƒè¯•ä»£ç 
```bash
# å—å½±å“çš„æ–‡ä»¶ï¼ˆéƒ¨åˆ†ï¼‰:
- tasks/interaction_tasks.py (å¤šå¤„ print å’Œ DEBUG æ—¥å¿—)
- app/life_system.py
- core/rag_decision_system.py
```

**å»ºè®®**:
- å°†æ‰€æœ‰ `print()` æ›¿æ¢ä¸º `logger.debug()`
- ç§»é™¤ç”Ÿäº§ç¯å¢ƒä¸­ä¸éœ€è¦çš„ DEBUG æ—¥å¿—
- æˆ–è€…ä½¿ç”¨ç¯å¢ƒå˜é‡æ§åˆ¶æ—¥å¿—çº§åˆ«

### 3. åˆ é™¤å¤‡ä»½æ–‡ä»¶
**é—®é¢˜**: ä»“åº“ä¸­åŒ…å«å¤‡ä»½æ–‡ä»¶
```bash
app/mattermost_client_å‰¯æœ¬.py
app/mattermost_client_å‰¯æœ¬2.py
```

**å»ºè®®**:
```bash
git rm app/mattermost_client_å‰¯æœ¬.py app/mattermost_client_å‰¯æœ¬2.py
git commit -m "chore: remove backup files"
```

### 4. æ”¹è¿›é”™è¯¯å¤„ç†
**å½“å‰é—®é¢˜ç¤ºä¾‹** (`tasks/daily_tasks.py:228-229`):
```python
except Exception as e:
    return {"status": "error", "message": str(e)}
```

**å»ºè®®æ”¹è¿›**:
```python
except httpx.TimeoutException as e:
    logger.error(f"ç”Ÿæˆæ—¥ç¨‹è¶…æ—¶: {e}")
    return {"status": "error", "message": "timeout", "details": str(e)}
except httpx.HTTPStatusError as e:
    logger.error(f"API è¿”å›é”™è¯¯çŠ¶æ€: {e.response.status_code}")
    return {"status": "error", "message": "http_error", "status_code": e.response.status_code}
except Exception as e:
    logger.exception(f"ç”Ÿæˆæ—¥ç¨‹å¤±è´¥: {e}")  # ä½¿ç”¨ logger.exception ä¼šè‡ªåŠ¨è®°å½•å †æ ˆ
    return {"status": "error", "message": str(e)}
```

---

## ğŸŸ¡ ä¸­ä¼˜å…ˆçº§ - è¿‘æœŸä¼˜åŒ–

### 5. ç»Ÿä¸€æ—¥å¿—æ ¼å¼
**é—®é¢˜**: æ—¥å¿—æ¶ˆæ¯æ ¼å¼ä¸ç»Ÿä¸€
- æœ‰äº›ä½¿ç”¨ `[module_name]` å‰ç¼€
- æœ‰äº›ä½¿ç”¨ä¸­æ–‡ï¼Œæœ‰äº›ä½¿ç”¨è‹±æ–‡
- æœ‰äº›ä½¿ç”¨è¡¨æƒ…ç¬¦å·

**å»ºè®®**: åˆ¶å®šç»Ÿä¸€çš„æ—¥å¿—è§„èŒƒ
```python
# æ¨èæ ¼å¼
logger.info("[ç”Ÿæˆæ—¥ç¨‹] å¼€å§‹ç”Ÿæˆ date=%s", date)
logger.debug("[ç”Ÿæˆæ—¥ç¨‹] AI å“åº”: %s", response[:100])
logger.error("[ç”Ÿæˆæ—¥ç¨‹] ç”Ÿæˆå¤±è´¥: %s", error, exc_info=True)
```

### 6. æ·»åŠ å¥åº·æ£€æŸ¥ç«¯ç‚¹
**å»ºè®®**: åœ¨ `app/main.py` ä¸­æ·»åŠ å¥åº·æ£€æŸ¥ç«¯ç‚¹

```python
@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼Œç”¨äºç›‘æ§ç³»ç»ŸçŠ¶æ€"""
    try:
        # æ£€æŸ¥ Redis è¿æ¥
        redis_ok = redis_client.ping()

        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        from utils.postgres_service import test_db_connection
        db_ok = test_db_connection()

        # æ£€æŸ¥ä»Šå¤©æ˜¯å¦æœ‰æ—¥ç¨‹æ•°æ®
        from app.life_system import LifeSystemQuery
        today = date.today()
        schedule = await LifeSystemQuery(today).get_daily_schedule_info()

        return {
            "status": "healthy",
            "redis": redis_ok,
            "database": db_ok,
            "has_today_schedule": schedule is not None,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@app.get("/health/celery")
async def celery_health():
    """Celery ä»»åŠ¡é˜Ÿåˆ—å¥åº·æ£€æŸ¥"""
    from tasks.celery_app import celery_app

    try:
        # æ£€æŸ¥ Celery workers æ˜¯å¦åœ¨çº¿
        stats = celery_app.control.inspect().stats()
        active = celery_app.control.inspect().active()

        return {
            "status": "healthy" if stats else "unhealthy",
            "workers": list(stats.keys()) if stats else [],
            "active_tasks": sum(len(tasks) for tasks in active.values()) if active else 0
        }
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}
```

### 7. æ”¹è¿› Celery ä»»åŠ¡ç›‘æ§
**å»ºè®®**: æ·»åŠ ä»»åŠ¡å¤±è´¥é‡è¯•æœºåˆ¶

```python
# tasks/daily_tasks.py
@shared_task(
    bind=True,
    max_retries=3,
    retry_backoff=True,
    retry_backoff_max=600,
    retry_jitter=True
)
def generate_daily_life_task(self, date: str | None = None):
    try:
        # ... ç°æœ‰ä»£ç  ...
    except httpx.TimeoutException as exc:
        # è¶…æ—¶æ—¶é‡è¯•
        logger.warning(f"ç”Ÿæˆæ—¥ç¨‹è¶…æ—¶ï¼Œå°†é‡è¯•: {exc}")
        raise self.retry(exc=exc, countdown=60)  # 60ç§’åé‡è¯•
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ—¥ç¨‹å¤±è´¥: {e}")
        return {"status": "error", "message": str(e)}
```

### 8. ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢
**å»ºè®®**: æ·»åŠ æ•°æ®åº“è¿æ¥æ± é…ç½®å’ŒæŸ¥è¯¢ä¼˜åŒ–

åœ¨ `utils/postgres_service.py` ä¸­:
```python
# æ·»åŠ è¿æ¥æ± é…ç½®
import psycopg2.pool

connection_pool = psycopg2.pool.ThreadedConnectionPool(
    minconn=1,
    maxconn=20,  # æ ¹æ®å®é™…è´Ÿè½½è°ƒæ•´
    host=settings.POSTGRES_HOST,
    database=settings.POSTGRES_DB,
    user=settings.POSTGRES_USER,
    password=settings.POSTGRES_PASSWORD
)

# æ·»åŠ æŸ¥è¯¢ç¼“å­˜ï¼ˆå¯¹äºä¸å¸¸å˜åŒ–çš„æ•°æ®ï¼‰
from functools import lru_cache

@lru_cache(maxsize=100)
def get_major_event_by_date_cached(date_str: str):
    # å¤§äº‹ä»¶æ•°æ®å¯ä»¥ç¼“å­˜ï¼Œå› ä¸ºä¸ä¼šé¢‘ç¹å˜åŒ–
    return get_major_event_by_date(date_str)
```

### 9. ç¯å¢ƒå˜é‡éªŒè¯
**å»ºè®®**: åœ¨å¯åŠ¨æ—¶éªŒè¯æ‰€æœ‰å¿…éœ€çš„ç¯å¢ƒå˜é‡

```python
# app/config.py
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # æ·»åŠ å¿…éœ€å­—æ®µéªŒè¯
    POSTGRES_USER: str
    POSTGRES_PASSWORD: str
    POSTGRES_DB: str
    REDIS_HOST: str = "redis"
    GEMINI_API_KEY: str
    MATTERMOST_HOST: str
    MATTERMOST_TOKEN: str

    # æ·»åŠ å¯åŠ¨æ—¶éªŒè¯
    @classmethod
    def validate_settings(cls):
        required = [
            'POSTGRES_USER', 'POSTGRES_PASSWORD', 'POSTGRES_DB',
            'REDIS_HOST', 'GEMINI_API_KEY', 'MATTERMOST_HOST', 'MATTERMOST_TOKEN'
        ]
        missing = [key for key in required if not getattr(settings, key, None)]
        if missing:
            raise ValueError(f"Missing required environment variables: {', '.join(missing)}")
```

---

## ğŸŸ¢ ä½ä¼˜å…ˆçº§ - é•¿æœŸæ”¹è¿›

### 10. æ·»åŠ å•å…ƒæµ‹è¯•
**å»ºè®®**: ä¸ºæ ¸å¿ƒåŠŸèƒ½æ·»åŠ å•å…ƒæµ‹è¯•

```python
# tests/test_life_system.py
import pytest
from app.life_system import generate_and_store_daily_life

@pytest.mark.asyncio
async def test_generate_daily_life():
    from datetime import date
    target_date = date.today()
    result = await generate_and_store_daily_life(target_date)
    assert result is not None
    assert "schedule_items" in result

# tests/test_tasks.py
def test_fetch_and_store_life_data_task():
    from tasks.life_data_tasks import fetch_and_store_life_data_task
    result = fetch_and_store_life_data_task()
    assert result["status"] in ["success", "triggered_generation"]
```

### 11. æ€§èƒ½ç›‘æ§
**å»ºè®®**: æ·»åŠ æ€§èƒ½ç›‘æ§å’Œ APM (Application Performance Monitoring)

```python
# å¯ä»¥ä½¿ç”¨ Prometheus + Grafana
# æˆ–è€…ç®€å•çš„è‡ªå®šä¹‰ç›‘æ§

from functools import wraps
import time

def monitor_performance(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start = time.time()
        result = await func(*args, **kwargs)
        duration = time.time() - start

        # è®°å½•åˆ° Redis æˆ–æ—¥å¿—
        logger.info(f"[æ€§èƒ½ç›‘æ§] {func.__name__} è€—æ—¶: {duration:.2f}s")

        # å¦‚æœè¶…è¿‡é˜ˆå€¼ï¼Œå‘é€å‘Šè­¦
        if duration > 30:
            logger.warning(f"[æ€§èƒ½è­¦å‘Š] {func.__name__} è€—æ—¶è¿‡é•¿: {duration:.2f}s")

        return result
    return wrapper

# ä½¿ç”¨ç¤ºä¾‹
@monitor_performance
async def generate_and_store_daily_life(target_date: date):
    # ... ç°æœ‰ä»£ç  ...
```

### 12. æ•°æ®å¤‡ä»½ç­–ç•¥
**å»ºè®®**: å®ç°è‡ªåŠ¨æ•°æ®å¤‡ä»½

```python
# tasks/backup_tasks.py
@shared_task
def backup_database():
    """æ¯å¤©å¤‡ä»½æ•°æ®åº“"""
    import subprocess
    from datetime import datetime

    backup_file = f"backups/db_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.sql"

    try:
        subprocess.run([
            "pg_dump",
            "-h", settings.POSTGRES_HOST,
            "-U", settings.POSTGRES_USER,
            "-d", settings.POSTGRES_DB,
            "-f", backup_file
        ], check=True)

        logger.info(f"æ•°æ®åº“å¤‡ä»½æˆåŠŸ: {backup_file}")

        # åˆ é™¤ 7 å¤©å‰çš„å¤‡ä»½
        cleanup_old_backups(days=7)

    except Exception as e:
        logger.error(f"æ•°æ®åº“å¤‡ä»½å¤±è´¥: {e}")

# åœ¨ celery_app.py ä¸­æ·»åŠ è°ƒåº¦
"backup-database": {
    "task": "tasks.backup_tasks.backup_database",
    "schedule": crontab(hour=2, minute=0),  # æ¯å¤©å‡Œæ™¨ 2 ç‚¹å¤‡ä»½
}
```

### 13. API é€Ÿç‡é™åˆ¶
**å»ºè®®**: æ·»åŠ  API é€Ÿç‡é™åˆ¶ï¼Œé˜²æ­¢æ»¥ç”¨

```python
# app/main.py
from fastapi import Request
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(429, _rate_limit_exceeded_handler)

@app.get("/generate-daily-life")
@limiter.limit("5/minute")  # æ¯åˆ†é’Ÿæœ€å¤š 5 æ¬¡è¯·æ±‚
async def generate_daily_life_endpoint(request: Request, target_date: str = None):
    # ... ç°æœ‰ä»£ç  ...
```

### 14. é…ç½®ç®¡ç†ä¼˜åŒ–
**å»ºè®®**: ä½¿ç”¨é…ç½®ä¸­å¿ƒæˆ–é…ç½®æ–‡ä»¶åˆ†å±‚

```
config/
  â”œâ”€â”€ base.yml          # åŸºç¡€é…ç½®
  â”œâ”€â”€ development.yml   # å¼€å‘ç¯å¢ƒ
  â”œâ”€â”€ production.yml    # ç”Ÿäº§ç¯å¢ƒ
  â””â”€â”€ local.yml         # æœ¬åœ°é…ç½®ï¼ˆä¸æäº¤åˆ° Gitï¼‰
```

### 15. ä»£ç è´¨é‡å·¥å…·
**å»ºè®®**: æ·»åŠ ä»£ç è´¨é‡æ£€æŸ¥å·¥å…·

```bash
# å®‰è£…å·¥å…·
pip install black flake8 mypy pylint isort

# pyproject.toml
[tool.black]
line-length = 100
target-version = ['py311']

[tool.isort]
profile = "black"
line_length = 100

[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true

# æ·»åŠ  pre-commit é’©å­
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/psf/black
    rev: 23.3.0
    hooks:
      - id: black

  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort

  - repo: https://github.com/pycqa/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 16. Redis ä½¿ç”¨ä¼˜åŒ–
**å½“å‰é—®é¢˜**:
- å¯èƒ½å­˜åœ¨ Redis è¿æ¥æ³„æ¼
- æ²¡æœ‰ä½¿ç”¨è¿æ¥æ± 

**å»ºè®®**:
```python
# utils/redis_manager.py
import redis.asyncio as aioredis
from redis.asyncio.connection import ConnectionPool

# ä½¿ç”¨å¼‚æ­¥è¿æ¥æ± 
pool = ConnectionPool(
    host=settings.REDIS_HOST,
    port=settings.REDIS_PORT,
    db=0,
    max_connections=50,
    decode_responses=True
)

async_redis_client = aioredis.Redis(connection_pool=pool)
```

### 17. ç¼“å­˜ç­–ç•¥
**å»ºè®®**: ä¸ºé¢‘ç¹æŸ¥è¯¢çš„æ•°æ®æ·»åŠ ç¼“å­˜

```python
from functools import lru_cache
import asyncio

# å†…å­˜ç¼“å­˜ + Redis ç¼“å­˜åŒå±‚ç­–ç•¥
async def get_daily_schedule_with_cache(date_str: str):
    # 1. å…ˆæŸ¥å†…å­˜ç¼“å­˜
    cache_key = f"schedule:{date_str}"

    # 2. æŸ¥ Redis ç¼“å­˜
    cached = await async_redis_client.get(cache_key)
    if cached:
        return json.loads(cached)

    # 3. æŸ¥æ•°æ®åº“
    schedule = get_daily_schedule_by_date(date_str)

    # 4. å†™å…¥ç¼“å­˜ï¼ˆ24å°æ—¶è¿‡æœŸï¼‰
    if schedule:
        await async_redis_client.setex(
            cache_key,
            86400,
            json.dumps(schedule, ensure_ascii=False)
        )

    return schedule
```

---

## ğŸ”’ å®‰å…¨æ€§æ”¹è¿›

### 18. æ•æ„Ÿä¿¡æ¯ä¿æŠ¤
**å»ºè®®**:
- ä¸è¦åœ¨æ—¥å¿—ä¸­è¾“å‡ºæ•æ„Ÿä¿¡æ¯ï¼ˆAPI keys, tokensï¼‰
- æ·»åŠ æ—¥å¿—è„±æ•å‡½æ•°

```python
# utils/logging_config.py
def sanitize_log_message(message: str) -> str:
    """è„±æ•å¤„ç†æ—¥å¿—æ¶ˆæ¯"""
    import re
    # éšè— API keys
    message = re.sub(r'(api[_-]?key["\s:=]+)[\w-]+', r'\1***', message, flags=re.IGNORECASE)
    # éšè— tokens
    message = re.sub(r'(token["\s:=]+)[\w-]+', r'\1***', message, flags=re.IGNORECASE)
    # éšè—å¯†ç 
    message = re.sub(r'(password["\s:=]+)[\w-]+', r'\1***', message, flags=re.IGNORECASE)
    return message
```

### 19. è¾“å…¥éªŒè¯
**å»ºè®®**: ä¸º API ç«¯ç‚¹æ·»åŠ è¾“å…¥éªŒè¯

```python
from pydantic import BaseModel, validator
from datetime import date

class DateInput(BaseModel):
    target_date: str

    @validator('target_date')
    def validate_date(cls, v):
        try:
            date.fromisoformat(v)
            return v
        except ValueError:
            raise ValueError('æ—¥æœŸæ ¼å¼å¿…é¡»æ˜¯ YYYY-MM-DD')

@app.get("/generate-daily-life")
async def generate_daily_life_endpoint(date_input: DateInput = Depends()):
    # ... ä½¿ç”¨éªŒè¯åçš„æ•°æ® ...
```

---

## ğŸ“ˆ ç›‘æ§å’Œå‘Šè­¦

### 20. æ·»åŠ å‘Šè­¦ç³»ç»Ÿ
**å»ºè®®**: å½“å…³é”®ä»»åŠ¡å¤±è´¥æ—¶å‘é€å‘Šè­¦

```python
# utils/alerting.py
import httpx

async def send_alert(title: str, message: str, level: str = "warning"):
    """å‘é€å‘Šè­¦é€šçŸ¥ï¼ˆå¯ä»¥ä½¿ç”¨ä¼ä¸šå¾®ä¿¡ã€é’‰é’‰ã€é‚®ä»¶ç­‰ï¼‰"""
    # ç¤ºä¾‹ï¼šå‘é€åˆ° Webhook
    webhook_url = settings.ALERT_WEBHOOK_URL

    if not webhook_url:
        logger.warning("æœªé…ç½®å‘Šè­¦ Webhookï¼Œè·³è¿‡å‘Šè­¦å‘é€")
        return

    try:
        await httpx.post(
            webhook_url,
            json={
                "title": title,
                "message": message,
                "level": level,
                "timestamp": datetime.now().isoformat()
            },
            timeout=5.0
        )
    except Exception as e:
        logger.error(f"å‘é€å‘Šè­¦å¤±è´¥: {e}")

# åœ¨å…³é”®ä»»åŠ¡ä¸­ä½¿ç”¨
@shared_task
def generate_daily_life_task(date: str | None = None):
    try:
        # ... ä»»åŠ¡é€»è¾‘ ...
    except Exception as e:
        asyncio.run(send_alert(
            title="æ—¥ç¨‹ç”Ÿæˆå¤±è´¥",
            message=f"ç”Ÿæˆ {date} çš„æ—¥ç¨‹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
            level="error"
        ))
        raise
```

---

## ğŸ“ æ–‡æ¡£æ”¹è¿›

### 21. API æ–‡æ¡£å®Œå–„
**å»ºè®®**: ä¸ºæ‰€æœ‰ API ç«¯ç‚¹æ·»åŠ è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²

```python
@app.get(
    "/generate-daily-life",
    summary="ç”Ÿæˆæ¯æ—¥æ—¥ç¨‹",
    description="ä¸ºæŒ‡å®šæ—¥æœŸç”Ÿæˆå¾·å…‹è¨æ–¯çš„æ¯æ—¥ç”Ÿæ´»æ—¥ç¨‹ï¼ŒåŒ…æ‹¬å¤©æ°”ã€æ´»åŠ¨å®‰æ’å’Œå¾®è§‚ç»å†",
    response_description="ç”Ÿæˆç»“æœï¼ŒåŒ…å«æˆåŠŸæ¶ˆæ¯æˆ–é”™è¯¯ä¿¡æ¯",
    tags=["æ—¥ç¨‹ç®¡ç†"]
)
async def generate_daily_life_endpoint(
    target_date: str = Query(
        None,
        description="ç›®æ ‡æ—¥æœŸï¼Œæ ¼å¼ä¸º YYYY-MM-DDã€‚å¦‚æœä¸æŒ‡å®šï¼Œé»˜è®¤ä¸ºä»Šå¤©",
        example="2025-12-12"
    )
):
    """
    ## åŠŸèƒ½è¯´æ˜
    è§¦å‘ç”ŸæˆæŒ‡å®šæ—¥æœŸçš„å¾·å…‹è¨æ–¯ç”Ÿæ´»æ—¥ç¨‹ã€‚

    ## å¤„ç†æµç¨‹
    1. éªŒè¯æ—¥æœŸæ ¼å¼
    2. è·å–å¤©æ°”ä¿¡æ¯
    3. ç”Ÿæˆæ—¥ç¨‹å®‰æ’
    4. ç”Ÿæˆå¾®è§‚ç»å†
    5. å­˜å‚¨åˆ°æ•°æ®åº“å’Œ Redis

    ## æ³¨æ„äº‹é¡¹
    - ç”Ÿæˆè¿‡ç¨‹å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼ˆ1-5åˆ†é’Ÿï¼‰
    - å¦‚æœæ—¥æœŸå·²å­˜åœ¨æ—¥ç¨‹ï¼Œå°†ä¼šæ›´æ–°
    - ç”Ÿæˆåä¼šè‡ªåŠ¨è§¦å‘äº¤äº’äº‹ä»¶æ”¶é›†
    """
    # ... ç°æœ‰ä»£ç  ...
```

---

## ğŸ¯ å®æ–½ä¼˜å…ˆçº§å»ºè®®

### ç«‹å³å¤„ç†ï¼ˆæœ¬å‘¨ï¼‰
1. âœ… ä¿®å¤è¶…æ—¶é—®é¢˜ï¼ˆå·²å®Œæˆï¼‰
2. æ¸…ç†è°ƒè¯•ä»£ç å’Œå¤‡ä»½æ–‡ä»¶
3. æ”¹è¿›é”™è¯¯å¤„ç†
4. æ·»åŠ å¥åº·æ£€æŸ¥ç«¯ç‚¹

### è¿‘æœŸä¼˜åŒ–ï¼ˆ2å‘¨å†…ï¼‰
5. ç»Ÿä¸€æ—¥å¿—æ ¼å¼
6. æ·»åŠ  Celery ä»»åŠ¡é‡è¯•
7. ç¯å¢ƒå˜é‡éªŒè¯
8. åŸºç¡€ç›‘æ§å’Œå‘Šè­¦

### é•¿æœŸæ”¹è¿›ï¼ˆ1ä¸ªæœˆå†…ï¼‰
9. æ·»åŠ å•å…ƒæµ‹è¯•
10. æ€§èƒ½ä¼˜åŒ–ï¼ˆç¼“å­˜ã€è¿æ¥æ± ï¼‰
11. æ•°æ®å¤‡ä»½ç­–ç•¥
12. ä»£ç è´¨é‡å·¥å…·é›†æˆ

---

## ğŸ“ éœ€è¦è®¨è®ºçš„é—®é¢˜

1. **æ•°æ®ä¿ç•™ç­–ç•¥**: å¾®è§‚ç»å†æ•°æ®åº”è¯¥ä¿ç•™å¤šä¹…ï¼Ÿ
2. **å‘Šè­¦é€šçŸ¥æ–¹å¼**: ä½¿ç”¨ä»€ä¹ˆæ¸ é“å‘é€å‘Šè­¦ï¼ˆä¼ä¸šå¾®ä¿¡ã€é‚®ä»¶ã€é’‰é’‰ï¼‰ï¼Ÿ
3. **ç›‘æ§æ–¹æ¡ˆ**: æ˜¯å¦éœ€è¦å¼•å…¥ Prometheus + Grafanaï¼Ÿ
4. **æµ‹è¯•è¦†ç›–ç‡ç›®æ ‡**: æœŸæœ›è¾¾åˆ°å¤šå°‘æµ‹è¯•è¦†ç›–ç‡ï¼Ÿ
5. **éƒ¨ç½²æ–¹å¼**: æ˜¯å¦è€ƒè™‘ CI/CD è‡ªåŠ¨åŒ–éƒ¨ç½²ï¼Ÿ

---

*æœ¬æ–‡æ¡£ä¼šæŒç»­æ›´æ–°ã€‚å¦‚æœ‰æ–°çš„æ”¹è¿›å»ºè®®ï¼Œè¯·åŠæ—¶è¡¥å……ã€‚*
